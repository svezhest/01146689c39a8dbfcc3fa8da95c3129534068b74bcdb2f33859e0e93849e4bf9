{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./../data/sentiment_texts.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так мы обрабатываем слова: обрезаем окончания для работы с падежами, убираем смайлики, символы и цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_word(word):\n",
    "    return stemmer.stem(''.join(ch for ch in word.lower() if ch.isalpha()))\n",
    "\n",
    "def transform_sentence(sentence: str) -> str:\n",
    "    words = filter(lambda w: len(w) > 0, re.split('[?!.,:; \\n\\t]', sentence))\n",
    "    return ' '.join(transform_word(word) for word in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготавливаем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9289/9289 [01:11<00:00, 129.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_text = []\n",
    "total_len = 0\n",
    "for text in tqdm(df.MessageText):\n",
    "    _words = filter(lambda w: len(w) > 0, re.split('[?!.,:; \\n\\t]', text))\n",
    "    transformed_words = filter(lambda w: True if w in words else False, (transform_word(word) for word in _words))\n",
    "    transformed_text.append(' '.join(transformed_words))\n",
    "    total_len += len(list(transformed_words))\n",
    "\n",
    "df['TransormedText'] = transformed_text\n",
    "total_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы для быстрого поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_idx = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    search_idx.append((row.SentimentScore, set(row.TransormedText.split())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем, как часто слова встречаются в {sentiment} окрашенных предложениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18929 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18929/18929 [00:43<00:00, 433.65it/s]\n"
     ]
    }
   ],
   "source": [
    "word_counts = defaultdict(lambda: defaultdict(int))\n",
    "for word in tqdm(words):\n",
    "    for score, sett in search_idx:\n",
    "        if word in sett:\n",
    "            word_counts[word][score] += 1\n",
    "    word_counts[word]['word'] = word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузим ещё небольшой датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_dataset = pd.read_csv('./../data/data.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И тоже посчитаем слова. В датасете другая разметка, ничего страшного, преобразуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words = defaultdict(int)\n",
    "\n",
    "search_idx_2 = []\n",
    "def score_to_categories(_score):\n",
    "    if _score < -0.6:\n",
    "        return 1\n",
    "    elif _score < -0.2:\n",
    "        return 2\n",
    "    elif _score < 0.2:\n",
    "        return 3\n",
    "    elif score < 0.6:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "for row in extra_dataset.itertuples():\n",
    "    text = row.title\n",
    "    transformed_words = []\n",
    "    for x in text.split():\n",
    "        transormed = transform_word(x)\n",
    "        if len(transormed) > 1:\n",
    "            extra_words[transormed] += 1\n",
    "            transformed_words.append(transormed)\n",
    "\n",
    "    search_idx_2.append((score_to_categories(row.score), set(transformed_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1526/1526 [00:00<00:00, 10833.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for word in tqdm(extra_words):\n",
    "    for score, sett in search_idx_2:\n",
    "        if word in sett:\n",
    "            word_counts[word][score] += 1\n",
    "    word_counts[word]['word'] = word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай сохраняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word_counts.values()).to_csv('word_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.read_csv('word_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная часть: считаем несложные метрики на подсчёте встречаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import typing as tp\n",
    "import pandas\n",
    "\n",
    "class WordScore:\n",
    "    def __init__(self, super_negative_count: float, negative_count: float, neutral_count: float, positive_count: float, super_positive_count: float):\n",
    "        self.super_negative_count = super_negative_count\n",
    "        self.negative_count = negative_count\n",
    "        self.neutral_count = neutral_count\n",
    "        self.positive_count = positive_count\n",
    "        self.super_positive_count = super_positive_count \n",
    "\n",
    "        # not to return\n",
    "        self.total_positive_count = self.super_positive_count + self.positive_count\n",
    "        self.total_negative_count = self.super_negative_count + self.negative_count\n",
    "        self.total_count = self.total_positive_count + self.total_negative_count\n",
    "        \n",
    "        _total_count = max(self.total_count, 1)\n",
    "\n",
    "        self.positive_proportion = self.total_positive_count / _total_count\n",
    "        self.negative_proportion = self.total_negative_count / _total_count\n",
    "        \n",
    "        # not to return\n",
    "        self.simple_score = -1 * self.total_negative_count + self.total_positive_count\n",
    "        self.score = -1 * self.super_negative_count + -0.1 * self.negative_count + 0.1 * self.positive_count + self.super_positive_count\n",
    "        self.score_extreme_only = -1 * self.super_negative_count + self.super_positive_count\n",
    "        \n",
    "        self.simple_score_relative = self.simple_score / max(self.total_negative_count + self.total_positive_count, 1)\n",
    "        self.score_relative = self.score / _total_count\n",
    "        self.score_extreme_only_relative = self.score_extreme_only / _total_count\n",
    "\n",
    "        self.meaningful_proportion = (self.super_positive_count + self.total_negative_count) / max(self.positive_count + self.neutral_count, 1)\n",
    "        self.extreme_proporion = (self.super_positive_count + self.super_negative_count) / max(self.positive_count + self.neutral_count + self.negative_count, 1)\n",
    "\n",
    "        self.certanty = (self.positive_proportion if self.score > 0 else (self.negative_proportion if self.score < 0 else 0)) * max(1, self.extreme_proporion * 10) * math.log(_total_count)\n",
    "\n",
    "    def get_array(self) -> list[float]:\n",
    "        return [self.super_negative_count,\n",
    "            self.negative_count,\n",
    "            self.neutral_count,\n",
    "            self.positive_count,\n",
    "            self.super_positive_count,\n",
    "            # self.total_positive_count,\n",
    "            # self.total_negative_count,\n",
    "            # self.total_count,\n",
    "            self.positive_proportion,\n",
    "            self.negative_proportion,\n",
    "            # self.simple_score,\n",
    "            # self.score,\n",
    "            # self.score_extreme_only,\n",
    "            self.simple_score_relative,\n",
    "            self.score_relative,\n",
    "            self.score_extreme_only_relative,\n",
    "\n",
    "            self.meaningful_proportion,\n",
    "            self.extreme_proporion,\n",
    "            \n",
    "            self.certanty]\n",
    "    \n",
    "FEAUTURES_LEN = 13\n",
    "\n",
    "def prepare_word_scores(counts_df: pandas.DataFrame) -> dict[str, list[float]]:\n",
    "    word_scores = {}\n",
    "    for _, row in counts_df.iterrows():\n",
    "        word_scores[row['word']] = WordScore(row['1'], row['2'], row['3'], row['4'], row['5']).get_array()\n",
    "    return word_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_word_metrics(text: str, word_scores: dict[str, list[float]]) -> list[float]:\n",
    "    metrics = []\n",
    "\n",
    "    sentence_word_scores = [word_scores[word] for word in text.split() if word in word_scores]\n",
    "    if len(sentence_word_scores) == 0:\n",
    "        sentence_word_scores.append([0] * FEAUTURES_LEN)\n",
    "\n",
    "    for idx in range(FEAUTURES_LEN):\n",
    "        for aggr_fn in (min, max, sum, np.mean):\n",
    "            metrics.append(aggr_fn(np.array([word_score[idx] for word_score in sentence_word_scores])))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_scores = prepare_word_scores(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это пойдёт в прод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json = json.dumps(word_scores)\n",
    "with open('word_scores_full.json', 'w') as f:\n",
    "    f.write(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И построим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_words = np.array([get_text_word_metrics(text, word_scores) for text in df.TransormedText])\n",
    "y = df.SentimentScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state 0\n",
      "model accuracy_score: 0.8196297890658631\n",
      "prediction time 0.049341440200805664 len test 2323\n",
      "always 1 accuracy_score: 0.008179078777442962\n",
      "always 2 accuracy_score: 0.09900990099009901\n",
      "always 3 accuracy_score: 0.38613861386138615\n",
      "always 4 accuracy_score: 0.40637107188979765\n",
      "always 5 accuracy_score: 0.08136030994403788\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = X_words\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X)[y], y, random_state=42)\n",
    "# я знаю про файнтюнинг, мне лень\n",
    "model = CatBoostClassifier(verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'random state {i}')\n",
    "print('model', 'accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('prediction time', time.time() - start, 'len test', len(y_test))\n",
    "print('always 1', 'accuracy_score:', accuracy_score(y_test, [1] * len(y_test)))\n",
    "print('always 2', 'accuracy_score:', accuracy_score(y_test, [2] * len(y_test)))\n",
    "print('always 3', 'accuracy_score:', accuracy_score(y_test, [3] * len(y_test)))\n",
    "print('always 4', 'accuracy_score:', accuracy_score(y_test, [4] * len(y_test)))\n",
    "print('always 5', 'accuracy_score:', accuracy_score(y_test, [5] * len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это отличный показатель! Обучимся на всём датасете и сохраним модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fd449e62620>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(verbose=False)\n",
    "_y = np.array(y)\n",
    "_X = np.array(X)\n",
    "_X = _X[_y != 0]\n",
    "_y = _y[_y != 0]\n",
    "model.fit(_X, _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как она работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(text):\n",
    "    return [get_text_word_metrics(' '.join(filter(lambda w: True if w in word_scores else False, (transform_word(word) for word in filter(lambda w: len(w) > 0, re.split('[?!.,:; \\n\\t]', text))))), word_scores)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]]\n",
      "[[3]]\n",
      "[[4]]\n",
      "[[3]]\n"
     ]
    }
   ],
   "source": [
    "t = 'газпром пушка ракета рекомендую к покупке не является иир прекрасные результаты обещают выплату дивидендов'\n",
    "print(model.predict(make_features(t)))\n",
    "\n",
    "t = 'на рынке сегодня паника'\n",
    "print(model.predict(make_features(t)))\n",
    "\n",
    "t = 'создаётся впечатление, что модель очень-очень тупая'\n",
    "print(model.predict(make_features(t)))\n",
    "\n",
    "t = 'продавать невыплата падение шорт шортим неудача'\n",
    "print(model.predict(make_features(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель имеет потенциал к улучшению."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
